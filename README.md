# transformers_nlp



1.Attention all you need: paper that introduced the transformer architecture on which bert is based.
